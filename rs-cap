#!/usr/bin/env python3

import pyrealsense2 as rs
import numpy as np
import matplotlib.pyplot as plt
import cv2
import click
import h5py


@click.command()
@click.option(
    '--display/--no-display', 
    default=False, 
    help='Display while recording.'
)
@click.option(
    '--depth-filename',
    required=True,
    help='Filename for depth video output (should end in .h5).'
)
@click.option(
    '--color-filename',
    required=True,
    help='Filename for color video output (should end in .avi).'
)
@click.option(
    '--frames',
    required=True,
    type=int,
    help='How many frames should we capture?'
)
def rscap(display, depth_filename, color_filename, frames):
    """
    Capture depth and color streams from stereo camera, and save
    the videos to the given filenames.
    """

    if not depth_filename.endswith('.h5') or not color_filename.endswith('.avi'):
        raise Exception('Output filename extensions are incorrect.')

    # TODO: Allow configurable resolution and FPS.
    DIMS = (1280, 720)
    FPS = 30

    # Record at most one minute of data.
    # MAX_FRAMES = FPS * 60
    MAX_FRAMES = None

    # RealSense configuration.
    config = rs.config()
    config.enable_stream(rs.stream.depth, DIMS[0], DIMS[1], rs.format.z16, FPS)
    config.enable_stream(rs.stream.color, DIMS[0], DIMS[1], rs.format.bgr8, FPS)

    # Pipeline for frame capture.
    pipeline = rs.pipeline()
    pipeline.start(config)

    # Create OpenCV video writer for the color stream.
    color_f = cv2.VideoWriter(color_filename, cv2.VideoWriter_fourcc(*'XVID'), FPS, DIMS)

    # Write depth frames in chunks for performance.
    depth_data_buf = np.zeros((frames, DIMS[1], DIMS[0]), dtype=np.uint16)

    # Use h5py to save the depth data.
    depth_f = h5py.File(depth_filename, 'w', libver='latest')
    depth_dset = depth_f.create_dataset(
        'depth', 
        (frames, DIMS[1], DIMS[0]), 
        dtype=np.uint16,
        # NOTE: specifying maxshape results in chunking anyway.
        # chunks=(DIMS[1], DIMS[0], FPS),
        maxshape=(MAX_FRAMES, DIMS[1], DIMS[0])
    )

    # TODO: Stopping condition (currently just C-c).
    for frame in range(frames):
        
        # Wait for frames.
        frames = pipeline.wait_for_frames()
        depth_frame = frames.get_depth_frame()
        color_frame = frames.get_color_frame()
        if not depth_frame or not color_frame: continue

        # Get np arrays from frames.
        # Get depth and color as numpy arrays.
        depth_data = np.asanyarray(depth_frame.as_frame().get_data())
        color_data = np.asanyarray(color_frame.as_frame().get_data())

        # Display the frames (if we should).
        if display:
            
            depth_colormap = cv2.applyColorMap(
                cv2.convertScaleAbs(depth_data, alpha=0.03), 
                cv2.COLORMAP_JET
            )
            cv2.imshow('depth', depth_colormap)
            cv2.imshow('color', color_data)
            cv2.waitKey(1)

        # Write color frames to feed.
        color_f.write(color_data)

        # Accumulate buffer.
        depth_data_buf[frame, :, :] = depth_data

    print('Captured ' + str(frames) + ' frames.')

    # Write the depth buffer.
    print('Writing depth dataset ...')
    depth_dset[:,:,:] = depth_data_buf

    # Release VideoWriter handles and clean up any windows.
    color_f.release()
    cv2.destroyAllWindows()


if __name__ == '__main__':
    rscap()
